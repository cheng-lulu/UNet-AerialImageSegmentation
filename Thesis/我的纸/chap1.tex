\begin{spacing}{2}
    \section{先行研究}
\end{spacing}
图像分割问题从计算机被用于处理的那天开始就是一个核心问题。通过总结之前的算法，我们也许可以提出一些新的方法。
\subsection{图像分割技术的历史}
图像分割技术的演进历史大概可以分为基于图论的方法、基于像素聚类的方法和基于深度语义的方法三段。其中基于图论的方法和基于像素聚类的方法都被视为传统图像分割技术。而最新的图像分割算法基本上都是基于语义的分割算法。

基于图论的方法把图像分割问题与图的最小割问题相关联，分割的原则是使划分后的子图在内部保持相似度最大，而子图之间的相似度保持最小。

机器学习中的聚类算法如K-means、谱聚类等也应用于图像分割问题。通常的思路是利用诸如颜色、亮度、纹理等特征对像素点进行聚类。

传统的图像分割算法中主要是基于底层的特征，而基于语义的分割算法可以基于图像中高层内容信息对图像进行分割。因此语义分割算法在对结构复杂，内部差异性大的物体进行分割的时候表现较传统图像分割技术好。

遥感图像中，既有道路、森林等有相对固定的纹理的物体，也有建筑、港口等较为复杂的物体。对于简单的物体的分割，传统的基于图论的方法和基于像素聚类的方法可能会对我们有所启示；而那些复杂的物体基于语义图像分割技术可能会有更好的效果。
\subsection{深度学习与图像分割}
作为深度学习中一个常见的任务，基于语义的图像分割技术已有了长足的发展。现如今，一个通用的框架已确定，那就是在前端使用神经网络对特征进行提取，后端再利用马尔可夫随机场等优化方案对前端的输出进行优化，输出分割图片。

2015年之前，人工神经网络在图像分类任务上表现良好。但在图像语义分割任务上的表现差强人意。2015年，加州大学伯克利分校的 Long 等人的论文\cite{long2015fully}发表。自此，一大批受全卷积网络启发的神经网络开始涌现，人工神经网络开始广泛应用于图像语义分割任务。
\subsubsection {全卷积网络与语义分割网络设计准则}
作为人工神经网络应用于图像语义分割的开山之作，全卷积网络现已有了广义和狭义两种定义。狭义上的全卷积网络指 Long 等人的论文\cite{long2015fully}中提出的用于图像语义分割的神经网络。而广义的全卷积网络则是指一类用全卷积层替代全连接层的神经网络。下面的全卷积网络指的是狭义上的全卷积网络。
\cite{long2015fully}为我们提供了三个语义分割网络设计准则：
\begin{enumerate}
    \item 用全卷积层替换全连接层来保留位置信息；
    \item 通过上采样还原因池化操作造成的位置信息损失；
    \item 利用深监督或跳跃连接结合浅层信息，优化输出。
\end{enumerate}
下面我对这三个准则进行阐述。
\paragraph{全连接层与全卷积层}
我们从人工神经网络的应用历史可以知道，人工神经网络最开始用于图像分类。一个经典的用于图像分类的网络，如\cite{krizhevsky2012imagenet}中提出的AlexNet，通过在卷积层之后连接上若干个全连接层，将卷积层提取的特征图映射成一个特征向量。这个特征向量在经过归一化处理之后，可以用来表示图像属于每一类的概率，进而达到对图像分类的目的。

图像分割任务也可以被视作一个分类任务，即通过将像素分到不同的类别达到分割的效果。全连接层将二维的图像压缩成了一位的特征向量从而丢失了定位像素的空间信息。因此在全卷积网络中，传统的用于图像分类的网络的全连接层被替换成了全卷积层。

在\cite{long2015fully}中，Long 等人对有广泛应用的分类网络 VGG16\cite{simonyan2014very} 进行改造，去掉了最后的全连接层，加上了全卷积层。丢弃全卷积层作为重要的用于图像分割的神经网络设计准则被广泛接受。不论是用于场景解析的 PSPNet\cite{zhao2017pyramid} 和 SegNet\cite{badrinarayanan2017segnet} 还是用于医疗图像分割的 U-Net\cite{ronneberger2015u} 都使用全卷积层来替换全连接层。


\paragraph{池化层与上采样}
池化层可以增加输入图像对一些小扰动的鲁棒性，更重要的是池化层增大了感受野，这对提取高层语义信息十分重要。但池化层与全连接层一样，对保留像素的位置信息是很不利的。因此如何恢复在池化层中丢失的位置信息是语义分割网络的重要议题。

在\cite{long2015fully}中，Long 等人提出通过对输入数据进行上采样恢复到输入图像的大小来补充位置信息。这篇论文中上采样不是使用简单的双线性插值，而是通过学习实现插值操作。然而，由于在池化操作中丢失部分信息，使得即使加上反卷积层的上采样操作也会产生粗糙的分割图。

除插值操作之外，其他受\cite{long2015fully}启发的论文中也提出了其他对抗池化层的方法，其中主流的思路有以下两种：

\begin{enumerate}
    \item 编码器-解码器结构
    
    编码器-解码器结构是一种常见的恢复位置信息的方法。比较著名的网络有SegNet\cite{badrinarayanan2017segnet}和下面将要使用的U-Net\cite{ronneberger2015u}。编码器中，使用池化层减小输入数据的空间维度；解码器则通过反卷积层来增大空间维度。
    \item 空洞卷积
    
    使用空洞卷积来替代池化层。空洞卷积可以在不降低空间维度的前提下增大感受野。使用空洞卷积的有DeepLab\cite{chen2014semantic}系列网络。但使用空洞卷积计算成本较编码器-解码器方案高，因此不适用于图像巨大的遥感图像处理。
\end{enumerate}
\paragraph{跳跃连接与深监督}
使用神经网络提取的特征，在浅层是简单的图像特征，如边界、颜色等。而深层由于感受野增大，我们可以提取更抽象的特征。为了获得更精确的语义分割结果，我们需要结合浅层语义信息。

上采样之后的结果还是十分粗糙。在\cite{long2015fully}中，Long等人将不同池化层的结果进行上采样之后进行加操作（summation）来优化输出。这种利用不同深度特征来优化输出的思路在其后的网络中也有迹可寻。

在\cite{ronneberger2015u}中，作者则是将上采样中大小差不多的层与下采样中不同深度的池化层进行叠操作（concatenation）之后再进行卷积操作。这样做的好处是在通过上采样恢复时可以利用浅层信息，从而达到更精准的分割效果。

深监督网络\cite{lee2015deeply}可以提高隐藏层学习过程的直接性和透明度。深监督网络的核心思想是为隐藏层提供集成的直接监督层，而不是仅在输出层提供监督。通过为每个隐藏层引入伴随目标函数来提供这种集成的直接隐藏层监督;这些伴随目标函数可以被视为学习过程中的附加（软）约束。

引入深监督的语义分割网络有HEDNet\cite{xie2015holistically}。虽然这个网络是用于边缘检测，但是作者将边缘检测看做是一个图像分割问题：即将图像分割为边缘和非边缘两类。该网络与\cite{long2015fully}一样改装了VGG系列网络。与\cite{long2015fully}不同的是，它在VGG网络的各个隐层输出损失函数而非\cite{long2015fully}那样进行加操作。

\cite{lee2015deeply}与\cite{long2015fully}这两种非编码器-解码器结构的网络采用了两种不同的利用浅层语义信息的方式。可以说跳跃连接和深监督是利用浅层语义信息的两种思路。